{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "data = pd.read_csv('mbti.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.95      0.96      0.95       376\n",
      "        ENFP       0.88      0.78      0.83       360\n",
      "        ENTJ       0.94      0.97      0.96       401\n",
      "        ENTP       0.86      0.84      0.85       344\n",
      "        ESFJ       0.98      1.00      0.99       382\n",
      "        ESFP       0.99      1.00      0.99       371\n",
      "        ESTJ       0.99      1.00      1.00       351\n",
      "        ESTP       0.97      1.00      0.99       391\n",
      "        INFJ       0.77      0.68      0.72       360\n",
      "        INFP       0.71      0.74      0.73       345\n",
      "        INTJ       0.82      0.78      0.80       379\n",
      "        INTP       0.80      0.83      0.82       344\n",
      "        ISFJ       0.96      0.99      0.98       350\n",
      "        ISFP       0.94      0.96      0.95       387\n",
      "        ISTJ       0.94      0.97      0.96       353\n",
      "        ISTP       0.92      0.93      0.93       369\n",
      "\n",
      "    accuracy                           0.90      5863\n",
      "   macro avg       0.90      0.90      0.90      5863\n",
      "weighted avg       0.90      0.90      0.90      5863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#stratify=data['type']\n",
    "X, y = data['posts'], data['type']\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X.values.reshape(-1, 1), y)\n",
    "X_resampled = X_resampled.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_resampled), y=y_resampled)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    # ('classifier', KNeighborsClassifier())\n",
    "    ('classifier', LogisticRegression(class_weight=dict(zip(np.unique(y_resampled), class_weights))))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#stratify=data['type']\n",
    "# lowercase=True, stop_words='english')\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)\n",
    "#     text = re.sub(r'\\d+', '', text)\n",
    "#     tokens = word_tokenize(text)\n",
    "#     stop_words = set(stopwords.words(\"english\"))\n",
    "#     tokens = [word for word in tokens if word not in stop_words]\n",
    "#     morph = MorphAnalyzer()\n",
    "#     tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "#     return \" \".join(tokens)\n",
    "\n",
    "# X, y = list(map(preprocess_text, data['posts'])), data['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INTJ']\n"
     ]
    }
   ],
   "source": [
    "s = 'There will be no results and you do not sum them up - it is not the end yet, why sit and sum it up.Happy New Year to all! All the best to everyone in the new year, hug everyone + lift them up!'\n",
    "print(model.predict([s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "INFP    1832\n",
      "INFJ    1470\n",
      "INTP    1304\n",
      "INTJ    1091\n",
      "ENTP     685\n",
      "ENFP     675\n",
      "ISTP     337\n",
      "ISFP     271\n",
      "ENTJ     231\n",
      "ISTJ     205\n",
      "ENFJ     190\n",
      "ISFJ     166\n",
      "ESTP      89\n",
      "ESFP      48\n",
      "ESFJ      42\n",
      "ESTJ      39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.56      0.49      0.52        41\n",
      "        ENFP       0.67      0.66      0.67       125\n",
      "        ENTJ       0.50      0.66      0.57        44\n",
      "        ENTP       0.64      0.65      0.64       135\n",
      "        ESFJ       0.13      0.29      0.18         7\n",
      "        ESFP       0.00      0.00      0.00         8\n",
      "        ESTJ       0.50      0.57      0.53         7\n",
      "        ESTP       0.73      0.53      0.62        15\n",
      "        INFJ       0.75      0.64      0.69       288\n",
      "        INFP       0.73      0.75      0.74       370\n",
      "        INTJ       0.62      0.69      0.66       193\n",
      "        INTP       0.77      0.72      0.75       293\n",
      "        ISFJ       0.83      0.64      0.72        45\n",
      "        ISFP       0.54      0.64      0.59        53\n",
      "        ISTJ       0.74      0.64      0.68        44\n",
      "        ISTP       0.56      0.72      0.63        67\n",
      "\n",
      "    accuracy                           0.68      1735\n",
      "   macro avg       0.58      0.58      0.57      1735\n",
      "weighted avg       0.69      0.68      0.68      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(lowercase=True, stop_words='english')),\n",
    "    # ('tfidf', CountVectorizer()),\n",
    "    ('classifier', LogisticRegression(class_weight=dict(zip(np.unique(y), class_weights))))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
