{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vsu70\\AppData\\Local\\Temp\\ipykernel_10736\\1549076654.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data[~data.applymap(lambda x: x == 'UNKNOWN').any(axis=1)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data = pd.read_csv('anime.csv')\n",
    "\n",
    "data = data[~data.applymap(lambda x: x == 'UNKNOWN').any(axis=1)]\n",
    "\n",
    "y = data['Score']\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "x_types = encoder.fit_transform(data[['Type']])\n",
    "x_types = pd.DataFrame(x_types, columns=encoder.get_feature_names_out(['Type']))\n",
    "\n",
    "x_episodes = pd.DataFrame(data['Episodes']).reset_index(drop=True)\n",
    "\n",
    "# encoder = OneHotEncoder(sparse_output=False)\n",
    "x_source = encoder.fit_transform(data[['Source']])\n",
    "x_source = pd.DataFrame(x_source, columns=encoder.get_feature_names_out(['Source']))\n",
    "\n",
    "# encoder = OneHotEncoder(sparse_output=False)\n",
    "x_rating = encoder.fit_transform(data[['Rating']])\n",
    "x_rating = pd.DataFrame(x_rating, columns=encoder.get_feature_names_out(['Rating']))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "x_producers = data['Producers'].str.split(', ')\n",
    "x_producers = mlb.fit_transform(x_producers)\n",
    "x_producers = pd.DataFrame(x_producers, columns=mlb.classes_)\n",
    "\n",
    "x_licensors = data['Licensors'].str.split(', ')\n",
    "x_licensors = mlb.fit_transform(x_licensors)\n",
    "x_licensors = pd.DataFrame(x_licensors, columns=mlb.classes_)\n",
    "\n",
    "x_studios = data['Studios'].str.split(', ')\n",
    "x_studios = mlb.fit_transform(x_studios)\n",
    "x_studios = pd.DataFrame(x_studios, columns=mlb.classes_)\n",
    "\n",
    "x_premiered = data['Premiered'].str.split(' ')\n",
    "x_season = pd.DataFrame(x_premiered.apply(lambda x: x[0]).tolist(), columns=['Season'])\n",
    "x_year = pd.DataFrame(x_premiered.apply(lambda x: x[1]).tolist(), columns=['Year'])\n",
    "x_year['Year'] = pd.to_numeric(x_year['Year'])\n",
    "\n",
    "# encoder = OneHotEncoder(sparse_output=False)\n",
    "x_season = encoder.fit_transform(x_season)\n",
    "x_season = pd.DataFrame(x_season, columns=encoder.get_feature_names_out(['Season']))\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_synopsis = vectorizer.fit_transform(data['Synopsis'])\n",
    "x_synopsis = pd.DataFrame(x_synopsis.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# X = pd.concat([x_types, x_episodes, x_rating, x_season, x_year, x_studios, x_licensors, x_producers, x_synopsis], axis=1)\n",
    "X = pd.concat([x_types, x_episodes, x_rating, x_season, x_year], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# print(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение алгоритмов при помощи sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5506963724475853\n",
      "MAE: 0.565099730458221\n",
      "MAE: 0.6628440942854689\n",
      "MAE: 0.5818611820596566\n",
      "MAE: 0.5277646359381031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=float)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5991580775966912\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegressionSGD:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.weights = np.zeros(n + 1)\n",
    "        X_b = np.c_[np.ones((m, 1)), X]\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(m):\n",
    "                random_index = np.random.randint(m)\n",
    "                xi = X_b[random_index:random_index+1]\n",
    "                yi = y[random_index]\n",
    "                gradient = 2 * xi.T.dot(xi.dot(self.weights) - yi)\n",
    "                self.weights -= self.learning_rate * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return X_b.dot(self.weights)\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=float)\n",
    "\n",
    "model = LinearRegressionSGD(learning_rate=0.01, epochs=1000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5738544474393532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNearestNeighbors:\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = np.linalg.norm(self.X_train - x, axis=1)\n",
    "            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "            nearest_labels = self.y_train[nearest_indices]\n",
    "            predictions.append(np.mean(nearest_labels))\n",
    "        return np.array(predictions)\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=float)\n",
    "\n",
    "model = KNearestNeighbors(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация решающего дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5518996065967602\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if len(set(y)) == 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return self.Node(value=np.mean(y))\n",
    "\n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "        if best_feature is None:\n",
    "            return self.Node(value=np.mean(y))\n",
    "\n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "\n",
    "        left = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return self.Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold\n",
    "                right_indices = X[:, feature] > threshold\n",
    "\n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "                    continue\n",
    "\n",
    "                left_mean = np.mean(y[left_indices])\n",
    "                right_mean = np.mean(y[right_indices])\n",
    "\n",
    "                loss = (np.sum((y[left_indices] - left_mean) ** 2) +\n",
    "                        np.sum((y[right_indices] - right_mean) ** 2))\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=float)\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.534441994674516\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if len(set(y)) == 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return self.Node(value=np.mean(y))\n",
    "\n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "        if best_feature is None:\n",
    "            return self.Node(value=np.mean(y))\n",
    "\n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "\n",
    "        left = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return self.Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold\n",
    "                right_indices = X[:, feature] > threshold\n",
    "\n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "                    continue\n",
    "\n",
    "                left_mean = np.mean(y[left_indices])\n",
    "                right_mean = np.mean(y[right_indices])\n",
    "\n",
    "                loss = (np.sum((y[left_indices] - left_mean) ** 2) +\n",
    "                        np.sum((y[right_indices] - right_mean) ** 2))\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)\n",
    "\n",
    "class RandomForestRegressor:\n",
    "    def __init__(self, n_estimators=10, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        for _ in range(self.n_estimators):\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample = X[indices]\n",
    "            y_sample = y[indices]\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(predictions, axis=0)\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=float)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=10, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5309886123446206\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if len(set(y)) == 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return self.Node(value=np.mean(y))\n",
    "\n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "        if best_feature is None:\n",
    "            return self.Node(value=np.mean(y))\n",
    "\n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "\n",
    "        left = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return self.Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold\n",
    "                right_indices = X[:, feature] > threshold\n",
    "\n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "                    continue\n",
    "\n",
    "                left_mean = np.mean(y[left_indices])\n",
    "                right_mean = np.mean(y[right_indices])\n",
    "\n",
    "                loss = (np.sum((y[left_indices] - left_mean) ** 2) +\n",
    "                        np.sum((y[right_indices] - right_mean) ** 2))\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        predictions = np.zeros_like(y)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            residuals = y - predictions\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals)\n",
    "            self.trees.append(tree)\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "        return predictions\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=float)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разведывательный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "INFP    1832\n",
      "INFJ    1470\n",
      "INTP    1304\n",
      "INTJ    1091\n",
      "ENTP     685\n",
      "ENFP     675\n",
      "ISTP     337\n",
      "ISFP     271\n",
      "ENTJ     231\n",
      "ISTJ     205\n",
      "ENFJ     190\n",
      "ISFJ     166\n",
      "ESTP      89\n",
      "ESFP      48\n",
      "ESFJ      42\n",
      "ESTJ      39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('mbti.csv')[:1000]\n",
    "X, y = data['posts'], data['type']\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english')\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация при помощи sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression f1_score: 0.48435489613633786\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight=dict(zip(np.unique(y), class_weights)))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"LogisticRegression f1_score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# model = KNeighborsClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(f\"KNeighborsClassifier f1_score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# model = DecisionTreeClassifier(class_weight=dict(zip(np.unique(y), class_weights)))\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(f\"DecisionTreeClassifier f1_score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# model = RandomForestClassifier(class_weight=dict(zip(np.unique(y), class_weights)))\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(f\"RandomForestClassifier f1_score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# model = GradientBoostingClassifier(n_estimators=5)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(f\"GradientBoostingClassifier f1_score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "if issparse(X_train):\n",
    "    X_train = X_train.toarray()\n",
    "if issparse(X_test):\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "\n",
    "class SoftmaxRegression:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Численная стабильность\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        m, n = X.shape\n",
    "        num_classes = len(np.unique(y))\n",
    "        self.weights = np.zeros((n + 1, num_classes))\n",
    "        X_b = np.c_[np.ones((m, 1)), X]\n",
    "\n",
    "        # One-hot encoding целевых меток\n",
    "        y_one_hot = np.zeros((m, num_classes))\n",
    "        y_one_hot[np.arange(m), y] = 1\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            logits = X_b.dot(self.weights)\n",
    "            probabilities = self.softmax(logits)\n",
    "            gradient = X_b.T.dot(probabilities - y_one_hot) / m\n",
    "            self.weights -= self.learning_rate * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        logits = X_b.dot(self.weights)\n",
    "        probabilities = self.softmax(logits)\n",
    "        return np.argmax(probabilities, axis=1)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "# Данные\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=int)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=int)\n",
    "\n",
    "model = SoftmaxRegression(learning_rate=0.01, epochs=1000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class KNearestNeighbors:\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = np.linalg.norm(self.X_train - x, axis=1)\n",
    "            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "            nearest_labels = self.y_train[nearest_indices]\n",
    "            # Используем мажоритарное голосование\n",
    "            unique, counts = np.unique(nearest_labels, return_counts=True)\n",
    "            predictions.append(unique[np.argmax(counts)])\n",
    "        return np.array(predictions)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "# Кодирование текстовых меток\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Преобразование разреженных матриц в плотные\n",
    "if issparse(X_train):\n",
    "    X_train = X_train.toarray()\n",
    "if issparse(X_test):\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "\n",
    "model = KNearestNeighbors(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "if issparse(X_train):\n",
    "    X_train = X_train.toarray()\n",
    "if issparse(X_test):\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if len(np.unique(y)) == 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return self.Node(value=self._majority_vote(y))\n",
    "\n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "        if best_feature is None:\n",
    "            return self.Node(value=self._majority_vote(y))\n",
    "\n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "\n",
    "        left = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return self.Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_gini = float('inf')\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold\n",
    "                right_indices = X[:, feature] > threshold\n",
    "\n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "                    continue\n",
    "\n",
    "                gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _gini_impurity(self, left, right):\n",
    "        def gini(labels):\n",
    "            _, counts = np.unique(labels, return_counts=True)\n",
    "            probs = counts / len(labels)\n",
    "            return 1 - np.sum(probs ** 2)\n",
    "\n",
    "        m = len(left) + len(right)\n",
    "        gini_left = gini(left)\n",
    "        gini_right = gini(right)\n",
    "        return (len(left) / m) * gini_left + (len(right) / m) * gini_right\n",
    "\n",
    "    def _majority_vote(self, y):\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        return unique[np.argmax(counts)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=int)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=int)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.235\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "if issparse(X_train):\n",
    "    X_train = X_train.toarray()\n",
    "if issparse(X_test):\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if len(np.unique(y)) == 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return self.Node(value=self._majority_vote(y))\n",
    "\n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "        if best_feature is None:\n",
    "            return self.Node(value=self._majority_vote(y))\n",
    "\n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "\n",
    "        left = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return self.Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_gini = float('inf')\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold\n",
    "                right_indices = X[:, feature] > threshold\n",
    "\n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "                    continue\n",
    "\n",
    "                gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _gini_impurity(self, left, right):\n",
    "        def gini(labels):\n",
    "            _, counts = np.unique(labels, return_counts=True)\n",
    "            probs = counts / len(labels)\n",
    "            return 1 - np.sum(probs ** 2)\n",
    "\n",
    "        m = len(left) + len(right)\n",
    "        gini_left = gini(left)\n",
    "        gini_right = gini(right)\n",
    "        return (len(left) / m) * gini_left + (len(right) / m) * gini_right\n",
    "\n",
    "    def _majority_vote(self, y):\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        return unique[np.argmax(counts)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, n_estimators=10, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        for _ in range(self.n_estimators):\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample = X[indices]\n",
    "            y_sample = y[indices]\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=int)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=int)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1, max_depth=1)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "if issparse(X_train):\n",
    "    X_train = X_train.toarray()\n",
    "if issparse(X_test):\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if len(np.unique(y)) == 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return self.Node(value=np.mean(y))\n",
    "\n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "        if best_feature is None:\n",
    "            return self.Node(value=np.mean(y))\n",
    "\n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "\n",
    "        left = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return self.Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold\n",
    "                right_indices = X[:, feature] > threshold\n",
    "\n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "                    continue\n",
    "\n",
    "                left_mean = np.mean(y[left_indices])\n",
    "                right_mean = np.mean(y[right_indices])\n",
    "\n",
    "                loss = (np.sum((y[left_indices] - left_mean) ** 2) +\n",
    "                        np.sum((y[right_indices] - right_mean) ** 2))\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)\n",
    "\n",
    "class GradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=10, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.init_prediction = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.init_prediction = np.mean(y)\n",
    "        predictions = np.full_like(y, self.init_prediction, dtype=float)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            residuals = y - predictions\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals)\n",
    "            self.trees.append(tree)\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        predictions = np.full(X.shape[0], self.init_prediction, dtype=float)\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "        return (predictions >= 0.5).astype(int)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=int)\n",
    "X_test = np.array(X_test, dtype=float)\n",
    "y_test = np.array(y_test, dtype=int)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=1, learning_rate=0.1, max_depth=1)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
